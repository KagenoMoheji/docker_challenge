##############################################################################################
# Spark/Hadoop/Javaのバージョン関係は下記リンクから確認
# (Javaはこっちから詳細ページ行って確認)https://spark.apache.org/documentation.html
# (Hadoopはこっちで確認)https://spark.apache.org/downloads.html
# (もしくはこっちでSparkダウンロードするときのHadoopバージョン確認)https://ftp.cc.uoc.gr/mirrors/apache/spark/
##############################################################################################

# Sparkバージョン
SPARK_VERSION=2.4.7
# Javaバージョン
JAVA_VERSION=8
# ワーカーノード数(docker-composeコマンドまたはlaunch_spark.shの引数で指定する場合はそちらの数字が優先して設定される)
SPARK_WORKER_CNT=1
# 各ワーカーノードに割り当てるCPUコア数．つまり各ワーカーノードが生成できるExecutor数．
SPARK_WORKER_CORES=4
# 各ワーカーノードに割り当てるメモリサイズ
SPARK_WORKER_MEMORY=4048m

# Hadoopバージョン
HADOOP_VERSION=2.7

# Pythonバージョン
PYTHON_VERSION=3.8

# GPUを使うか
USE_GPU=0