# --------------------------------------------------------------------------
# About Spark
# Spark/Hadoop/Java/Scalaのバージョン関係は下記リンクから確認
# (Javaはこっちから詳細ページ行って確認)https://spark.apache.org/documentation.html
# (Hadoopはこっちで確認)https://spark.apache.org/downloads.html
# (もしくはこっちでSparkダウンロードするときのHadoopバージョン確認)https://ftp.cc.uoc.gr/mirrors/apache/spark/
# --------------------------------------------------------------------------
# Sparkバージョン
SPARK_VERSION=2.4.7
# Javaバージョン
JAVA_VERSION=8
# ワーカーノードに割り当てるポート番号の終端
SPARK_WORKER_PORT_END=8089
# ワーカーノード数(docker-composeコマンドまたはlaunch_spark.shの引数で指定する場合はそちらの数字が優先して設定される)
SPARK_WORKER_CNT=1
# 各ワーカーノードに割り当てるCPUコア数．つまり各ワーカーノードが生成できるExecutor数．
SPARK_WORKER_CORES=2
# 各ワーカーノードに割り当てるメモリサイズ
SPARK_WORKER_MEMORY=4048m

# Hadoopバージョン
HADOOP_VERSION=2.7

# コードを置くディレクトリとか，ノード間・ノード&JupyterLab間の共有ディレクトリがマウントするホスト側のディレクトリ．docker-compose.ymlからの相対パスで，「./」の次から始まるディレクトリの文字列を設定する．
# 例：src
SHARED_WORKSPACE_HOST=src
# 上記のコンテナ側のディレクトリ．「/」から始まる文字列で．
# 例：/opt/workspace
SHARED_WORKSPACE_CONTAINER=/opt/workspace


# --------------------------------------------------------------------------
# About JupyterLab
# Pythonのバージョンリスト：https://www.python.org/ftp/python/
# ScalaのバージョンはJava同様にSparkのドキュメントから確認．
# --------------------------------------------------------------------------
# Pythonバージョン
PYTHON_VERSION=3.7.9

# Scalaバージョン
SCALA_VERSION=2.12.12

# GPUを使うか
USE_GPU=0